import torch.nn as nn

class self_attention(nn.Module):

    def __init__(self,input_dims):

        super().__init__():
        self.qkv = nn.Module()

    